- 互斥：同一时刻只允许一个线程访问共享资源
- 同步：线程之间的通信和协作

# 一、Syncronized对比Lock

## lock

1. 能够响应中断

- 持有锁A的线程在尝试获取锁B失败，进入阻塞状态，如果发生死锁，将没有机会唤醒阻塞线程
- 如果处于阻塞状态的线程能够响应中断信号，那阻塞线程就有机会释放曾经持有的锁A


2. 支持超时

- 如果线程在一段时间内没有获得锁，不是进入阻塞状态，而是返回一个错误
- 那么该线程也有机会释放曾经持有的锁

3. 非阻塞地获取锁

- 如果尝试获取锁失败，不是进入阻塞状态，而是直接返回，那么该线程也有机会释放曾经持有的锁

```java
// java.util.concurrent.locks.Lock接口
// 能够响应中断
void lockInterruptibly() throws InterruptedException;
// 支持超时（同时也能够响应中断）
boolean tryLock(long time, TimeUnit unit) throws InterruptedException;
// 非阻塞地获取锁
boolean tryLock();
```

4. volatile修饰的state变量保证可见性和有序性，unsafe类的CAS保证原子性(CPU级别的指令)


## synchronized

synchronize实现的锁本质上是一种阻塞锁，也就是说多个线程要排队访问同一个共享对象。

synchronized是无法禁止指令重排和处理器优化的，从双重校验单例可以看出

synchronized保证的有序性是多个线程之间的有序性，即被加锁的内容要按照顺序被多个线程执行。但是其内部的同步代码还是会发生重排序，只不过由于编译器和处理器都遵循as-if-serial语义，所以我们可以认为这些重排序在单线程内部可忽略。



## volatile

volatile是Java虚拟机提供的一种轻量级同步机制，他是基于内存屏障实现的。说到底，他并不是锁，所以他不会有synchronized带来的阻塞和性能损耗的问题。



# 二、wait/notify对比await/signal

notify()的风险：可能导致某些线程永远不会被通知到
- 假设有资源A、B、C、D，线程1~4都对应同一个互斥锁L
- 线程1申请到了AB，线程2申请到了CD
- 此时线程3申请AB，会进入互斥锁L的等待队列L，线程4申请CD，也会进入互斥锁L的等待队列L
- 线程1归还AB，通过notify()来通知互斥锁L的等待队列R中的线程，假设为线程4（先被移动到等待队列R）
- 但线程4申请的是CD，不满足条件，执行wait()，而真正该被唤醒的线程3就再也没有机会被唤醒了

# 三、可见性

1. Java多线程的可见性是通过Happens-Before规则来保证的

- synchronized的可见性保证：synchronized的解锁Happens-Before于后续对这个锁的加锁
- JUC中Lock的可见性保证：利用了volatile相关的Happens-Before规则

2. ReentrantLock内部持有一个volatile的成员变量state，加锁和解锁时都会读写state

- 执行value++之前，执行lock，会读写volatile变量state
- 执行value++之后，执行unlock，会读写volatile变量state
- 相关的Happens-Before规则

    `顺序性规则`
    对于线程T1，value++ Happens-Before unlock()
    对于线程T2，lock() Happens-Before 读取value

    `volatile变量规则`
    对于线程T1，unlock()会执行state=1
    对于线程T2，lock()会先读取state
    volatile变量的写操作 Happens-Before volatile变量的读操作
    因此线程T1的unlock Happens-Before 线程T2的lock，与synchronized非常类似

    `传递性规则`：线程T1的value++ Happens-Before 线程T2的lock()


3. volatile可见性原理

- 在生成汇编指令时会在volatile修饰的共享变量进行写操作时多出Lock前缀指令。
- Lock前缀指令会引起CPU缓存写回主内存
- 一个CPU缓存写回主内存会导致其他CPU缓存了该内存地址的数据失效(缓存一致性协议)
- 缓存一致性协议保证每个CPU通过嗅探在总线上传播的数据来检查自己缓存的值是不是修改。



# 四、有序性

内存屏障

JMM采取了保守策略：

- 在每个volatile写操作的前面插入一个StoreStore屏障；
- 在每个volatile写操作的后面插入一个StoreLoad屏障；
- 在每个volatile读操作的后面插入一个LoadLoad屏障；
- 在每个volatile读操作的后面插入一个LoadStore屏障。

需要注意的是：volatile写是在前面和后面分别插入内存屏障，而volatile读操作是在后面插入两个内存屏障

- StoreStore屏障：禁止上面的普通写和下面的volatile写重排序；
- StoreLoad屏障：防止上面的volatile写与下面可能有的volatile读/写重排序
- LoadLoad屏障：禁止下面所有的普通读操作和上面的volatile读重排序
- LoadStore屏障：禁止下面所有的普通写操作和上面的volatile读重排序

下面以两个示意图进行理解，图片摘自相当好的一本书《java并发编程的艺术》



# 五、生命周期

1. NEW(初始化状态)
2. RUNNABLE(可运行 / 运行状态) 
3. BLOCKED(阻塞状态)
4. WAITING(无时限等待)
5. TIMED_WAITING(有时限等待) 
6. TERMINATED(终止状态)

# 六、死锁

避免死锁的发生

1. 对于“占用且等待”这个条件，我们可以一次性申请所有的资源，这样就不存在等待了。
2. 对于“不可抢占”这个条件，占用部分资源的线程进一步申请其他资源时，如果申请不到，可
以主动释放它占有的资源，这样不可抢占这个条件就破坏掉了。
3. 对于“循环等待”这个条件，可以靠按序申请资源来预防。所谓按序申请，是指资源是有线性
顺序的，申请的时候可以先申请资源序号小的，再申请资源序号大的，这样线性化后自然就不 存在循环了。

# 七、Happen-Before

1. 程序的顺序性规则

这条规则是指在一个线程中，按照程序顺序，前面的操作 Happens-Before 于后续的任意 操作。

2. volatile 变量规则

这条规则是指对一个 volatile 变量的写操作， Happens-Before 于后续对这个 volatile
变量的读操作。

3. 传递性

这条规则是指如果 A Happens-Before B，且 B Happens-Before C，那么 A Happens-
Before C。

4. 管程中锁的规则

这条规则是指对一个锁的解锁 Happens-Before 于后续对这个锁的加锁。

5. 线程 start() 规则

这条是关于线程启动的。它是指主线程 A 启动子线程 B 后，子线程 B 能够看到主线程在
启动子线程 B 前的操作。

6. 线程 join() 规则

这条是关于线程等待的。它是指主线程 A 等待子线程 B 完成(主线程 A 通过调用子线程 B 的 join() 方法实现)，当子线程 B 完成后(主线程 A 中 join() 方法返回)，主线程能够看到子线程的操作。当然所谓的“看到”，指的是对共享变量的操作。


# 参考

- http://zhongmingmao.me/2019/05/05/java-concurrent-lock/
- http://zhongmingmao.me/2019/04/22/java-concurrent-wait-notify/
- http://zhongmingmao.me/2018/12/30/jvm-basic-synchronized/
- https://juejin.im/post/5ae9b41b518825670b33e6c4
- https://juejin.im/post/5d5c9fbce51d4561cd246641

